{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9487262,"sourceType":"datasetVersion","datasetId":5771710}],"dockerImageVersionId":30775,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import necessary libraries\nimport os\nimport pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import make_scorer, mean_absolute_error\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\n\n# Specify the input directory\ninput_dir = '/kaggle/input/sales-data-set/'\n\n# Load the datasets (set low_memory=False to handle mixed types)\ntrain_data = pd.read_csv(os.path.join(input_dir, 'train.csv'), low_memory=False)\ntest_data = pd.read_csv(os.path.join(input_dir, 'test.csv'), low_memory=False)\nstore_data = pd.read_csv(os.path.join(input_dir, 'store.csv'))\n\n# Merge train data with store data\ntrain_data = train_data.merge(store_data, on='Store', how='left')\n\n# Convert date columns to datetime format with automatic format detection\ntrain_data['Date'] = pd.to_datetime(train_data['Date'], errors='coerce')\ntest_data['Date'] = pd.to_datetime(test_data['Date'], errors='coerce')\n\n# Drop rows with missing target variable or features\ntrain_data = train_data.dropna(subset=['Sales'])\nX_train = train_data.drop(columns=['Sales', 'Date'])\ny_train = train_data['Sales']\n\n# Prepare test data features\nX_test = test_data.drop(columns=['Id', 'Date'])\n\n# Check for missing values in features\nX_train = X_train.fillna(0)  # Replace NaNs with 0 or consider using an imputer\n\n# Define categorical and numerical features\ncategorical_features = ['StoreType', 'Assortment', 'StateHoliday']\nnumerical_features = ['DayOfWeek', 'Open', 'Promo', 'SchoolHoliday', \n                     'CompetitionDistance', 'CompetitionOpenSinceMonth', \n                     'CompetitionOpenSinceYear', 'Promo2', \n                     'Promo2SinceWeek', 'Promo2SinceYear']\n\n# Create a preprocessing pipeline\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', Pipeline(steps=[\n            ('imputer', SimpleImputer(strategy='mean')), \n            ('scaler', StandardScaler())\n        ]), numerical_features),\n        ('cat', OneHotEncoder(), categorical_features)\n    ]\n)\n\n# Create the complete pipeline with a regressor\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('regressor', RandomForestRegressor(random_state=42))\n])\n\n# Define hyperparameters for tuning\nparam_grid = {\n    'regressor__n_estimators': [50, 100, 200],\n    'regressor__max_depth': [None, 10, 20, 30],\n    'regressor__min_samples_split': [2, 5, 10],\n    'regressor__min_samples_leaf': [1, 2, 4]\n}\n\n# Setup GridSearchCV\nmae_scorer = make_scorer(mean_absolute_error)\ngrid_search = GridSearchCV(pipeline, param_grid, scoring=mae_scorer, cv=5, n_jobs=-1)\n\n# Fit the GridSearchCV\ngrid_search.fit(X_train, y_train)\n\n# Print best parameters and best score\nprint(\"Best parameters found: \", grid_search.best_params_)\nprint(\"Best cross-validation MAE: \", grid_search.best_score_)\n\n# Make predictions on the test data using the best estimator\nbest_model = grid_search.best_estimator_\npredictions = best_model.predict(X_test)\n\n# Prepare submission dataframe\nsubmission = test_data[['Id']].copy()\nsubmission['Sales'] = predictions\n\n# Save the submission file to /kaggle/working/\nsubmission_file_path = '/kaggle/working/submission.csv'\nsubmission.to_csv(submission_file_path, index=False)\n\n# Display the first few rows of the submission\nprint(\"Submission Data:\")\nprint(submission.head())\n\n# Confirm where the file has been saved\nprint(f'Submission file saved to: {submission_file_path}')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T05:09:33.342379Z","iopub.execute_input":"2024-09-28T05:09:33.342901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary libraries\nimport os\nimport pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\n\n# Specify the input directory\ninput_dir = '/kaggle/input/sales-data-set/'\n\n# Load the datasets (set low_memory=False to handle mixed types)\ntrain_data = pd.read_csv(os.path.join(input_dir, 'train.csv'), low_memory=False)\ntest_data = pd.read_csv(os.path.join(input_dir, 'test.csv'), low_memory=False)\nstore_data = pd.read_csv(os.path.join(input_dir, 'store.csv'))\n\n# Merge train data with store data\ntrain_data = train_data.merge(store_data, on='Store', how='left')\n\n# Convert date columns to datetime format with automatic format detection\ntrain_data['Date'] = pd.to_datetime(train_data['Date'], errors='coerce')\ntest_data['Date'] = pd.to_datetime(test_data['Date'], errors='coerce')\n\n# Check for missing values\nprint(\"Missing values in training data:\")\nprint(train_data.isnull().sum())\n\n# Drop rows with missing target variable or features\ntrain_data = train_data.dropna(subset=['Sales'])\nX_train = train_data.drop(columns=['Sales', 'Date'])\ny_train = train_data['Sales']\n\n# Prepare test data features\nX_test = test_data.drop(columns=['Id', 'Date'])\n\n# Check for missing values in features\nX_train = X_train.fillna(0)  # Replace NaNs with 0 or consider using an imputer\n\n# Define categorical and numerical features\ncategorical_features = ['StoreType', 'Assortment', 'StateHoliday']\nnumerical_features = ['DayOfWeek', 'Open', 'Promo', 'SchoolHoliday', \n                     'CompetitionDistance', 'CompetitionOpenSinceMonth', \n                     'CompetitionOpenSinceYear', 'Promo2', \n                     'Promo2SinceWeek', 'Promo2SinceYear']\n\n# Create a preprocessing pipeline\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')), \n                                 ('scaler', StandardScaler())]), numerical_features),\n        ('cat', OneHotEncoder(), categorical_features)\n    ]\n)\n\n# Create the complete pipeline with a regressor\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('regressor', RandomForestRegressor(random_state=42))\n])\n\n# Fit the pipeline on the training data\npipeline.fit(X_train, y_train)\n\n# Make predictions on the test data\npredictions = pipeline.predict(X_test)\n\n# Prepare submission dataframe\nsubmission = test_data[['Id']].copy()\nsubmission['Sales'] = predictions\n\n# Save the submission file to /kaggle/working/\nsubmission_file_path = '/kaggle/working/submission.csv'\nsubmission.to_csv(submission_file_path, index=False)\n\n# Display the first few rows of the submission\nprint(\"Submission Data:\")\nprint(submission.head())\n\n# Confirm where the file has been saved\nprint(f'Submission file saved to: {submission_file_path}')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]}]}